{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Debug Feature Extraction\n",
    "\n",
    "Step-by-step investigation of the extraction algorithm with k>1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x112e3f530>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.config import SyntheticConfig, ExtractionConfig\n",
    "from src.synthetic import generate_feature_basis, generate_representations\n",
    "from src.extraction import (\n",
    "    cluster_by_neighbors,\n",
    "    resolve_tau,\n",
    "    compute_nullspace,\n",
    "    extract_feature,\n",
    "    find_neighbors\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d=16, n=16, k=3\n",
      "sparsity_mode=fixed\n",
      "tau=None, neg_tau=None\n"
     ]
    }
   ],
   "source": [
    "syn_config = SyntheticConfig(\n",
    "    d=16,\n",
    "    n=16,\n",
    "    epsilon=0.0,\n",
    "    num_representations=1000,\n",
    "    sparsity_mode=\"fixed\",  # Options: \"fixed\", \"bernoulli_gaussian\"\n",
    "    k=3,  # For bernoulli_gaussian: theta = k/n, E[||z||_0] = k\n",
    "    coef_min_floor=0.3,  # Only used for non-BG modes\n",
    "    positive_only=True,  # BG allows negative by default\n",
    ")\n",
    "ext_config = ExtractionConfig(\n",
    "    epsilon=0.0,\n",
    ")\n",
    "\n",
    "print(f\"d={syn_config.d}, n={syn_config.n}, k={syn_config.k}\")\n",
    "print(f\"sparsity_mode={syn_config.sparsity_mode}\")\n",
    "print(f\"tau={ext_config.tau}, neg_tau={ext_config.neg_tau}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gen-header",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "generate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: torch.Size([16, 16])\n",
      "Representations shape: torch.Size([1002, 16])\n",
      "Coefficients shape: torch.Size([1002, 16])\n"
     ]
    }
   ],
   "source": [
    "features = generate_feature_basis(syn_config.d, syn_config.n, syn_config.epsilon)\n",
    "representations_old, coefficients_old = generate_representations(features, syn_config)\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Representations shape: {representations.shape}\")\n",
    "print(f\"Coefficients shape: {coefficients.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6976084f-0d72-4a63-817d-d7f65770939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mono_coeff = torch.nn.functional.one_hot(torch.tensor(9), num_classes=syn_config.n).float()\n",
    "mono_repr = mono_coeff @ features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "71c10a76-cef2-42e6-ae7a-f29d8e4403d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = torch.vstack([representations_old, mono_repr])\n",
    "coefficients = torch.vstack([coefficients_old, mono_coeff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b41e8ae4-1666-4ec8-9291-a4bced2d0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_idx = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1a7d0f67-1a0f-47c6-ba5c-fce263c66a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = representations[target_idx], coefficients[target_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "active-features",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repr 0: active features = {1, 11, 4}\n",
      "repr 1: active features = {8, 13, 14}\n",
      "repr 2: active features = {11, 3, 7}\n",
      "repr 3: active features = {3, 6, 14}\n",
      "repr 4: active features = {8, 9, 11}\n"
     ]
    }
   ],
   "source": [
    "def get_active_features(coef_row: torch.Tensor) -> set[int]:\n",
    "    return set(torch.where(coef_row != 0)[0].tolist())\n",
    "\n",
    "repr_features = [get_active_features(coefficients[i]) for i in range(representations.shape[0])]\n",
    "\n",
    "# show first few\n",
    "for i in range(5):\n",
    "    print(f\"repr {i}: active features = {repr_features[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "82980800-2f16-4295-a6d2-b69f4f05c08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_active_features(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sim-header",
   "metadata": {},
   "source": [
    "## Cosine Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cosine-sim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target repr -1 has features: {9}\n",
      "Shares feature: 196, No shared: 804\n"
     ]
    }
   ],
   "source": [
    "norms = torch.norm(representations, dim=1)\n",
    "cos_sim_matrix = (representations @ representations.T) / (norms[:, None] * norms[None, :] + 1e-8)\n",
    "\n",
    "# Pick a specific representation to analyze\n",
    "target_idx = -1\n",
    "target_features = repr_features[target_idx]\n",
    "print(f\"Target repr {target_idx} has features: {target_features}\")\n",
    "\n",
    "# Separate representations by whether they share any feature with target\n",
    "shares_feature = [i for i in range(syn_config.num_representations) if repr_features[i] & target_features]\n",
    "no_shared_feature = [i for i in range(syn_config.num_representations) if not (repr_features[i] & target_features)]\n",
    "\n",
    "print(f\"Shares feature: {len(shares_feature)}, No shared: {len(no_shared_feature)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "sim-distribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharing a feature:\n",
      "  min=0.2679, max=0.9114, mean=0.5441\n",
      "Not sharing:\n",
      "  min=0.0000, max=0.0000, mean=0.0000\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarities to target\n",
    "target_sims = cos_sim_matrix[target_idx]\n",
    "\n",
    "sims_sharing = target_sims[shares_feature].abs()\n",
    "sims_not_sharing = target_sims[no_shared_feature].abs()\n",
    "\n",
    "print(\"Sharing a feature:\")\n",
    "print(f\"  min={sims_sharing.min():.4f}, max={sims_sharing.max():.4f}, mean={sims_sharing.mean():.4f}\")\n",
    "print(\"Not sharing:\")\n",
    "print(f\"  min={sims_not_sharing.min():.4f}, max={sims_not_sharing.max():.4f}, mean={sims_not_sharing.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cluster-header",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "clustering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tau = 0.0150\n",
      "Number of clusters: 473\n",
      "Neighbor set sizes: min=197, max=534, mean=489.5\n"
     ]
    }
   ],
   "source": [
    "tau = resolve_tau(ext_config, syn_config)\n",
    "print(f\"Using tau = {tau:.4f}\")\n",
    "\n",
    "clusters = cluster_by_neighbors(representations, tau)\n",
    "print(f\"Number of clusters: {len(clusters)}\")\n",
    "\n",
    "# Show cluster sizes\n",
    "neighbor_sizes = [len(ns) for ns in clusters.keys()]\n",
    "print(f\"Neighbor set sizes: min={min(neighbor_sizes)}, max={max(neighbor_sizes)}, mean={sum(neighbor_sizes)/len(neighbor_sizes):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8d280fc4-3f5e-42f3-9951-291ec397bbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbor_indices = find_neighbors(representations, target_idx, tau)\n",
    "# target = representations[target_idx]\n",
    "\n",
    "# norms = torch.norm(representations, dim=1)\n",
    "# target_norm = norms[target_idx]\n",
    "\n",
    "# # dots = representations @ target\n",
    "# # cosine_sims = dots / (norms * target_norm + 1e-8)\n",
    "\n",
    "# # # Find neighbors using absolute cosine similarity\n",
    "# # # This catches both aligned (+) and anti-aligned (-) representations\n",
    "# # neighbor_mask = torch.abs(cosine_sims) >= tau\n",
    "# # neighbor_indices = torch.where(neighbor_mask)[0]\n",
    "neighbor_indices_items = [i.item() for i in neighbor_indices]\n",
    "len(neighbor_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-cluster-header",
   "metadata": {},
   "source": [
    "## Analyze Single Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "single-cluster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive set size: 197\n",
      "Negative set size: 804\n"
     ]
    }
   ],
   "source": [
    "neighbor_set = set(neighbor_indices_items)\n",
    "pos_indices = neighbor_indices_items\n",
    "neg_indices = [i for i in range(representations.shape[0]) if i not in neighbor_set]\n",
    "\n",
    "print(f\"Positive set size: {len(pos_indices)}\")\n",
    "print(f\"Negative set size: {len(neg_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "feature-counts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature counts in positive set:\n",
      "  Feature 9: 197/197 (100%)\n",
      "  Feature 10: 36/197 (18%)\n",
      "  Feature 13: 32/197 (16%)\n",
      "  Feature 5: 30/197 (15%)\n",
      "  Feature 8: 28/197 (14%)\n",
      "  Feature 4: 28/197 (14%)\n",
      "  Feature 11: 27/197 (14%)\n",
      "  Feature 1: 27/197 (14%)\n",
      "  Feature 7: 26/197 (13%)\n",
      "  Feature 2: 26/197 (13%)\n",
      "  Feature 3: 26/197 (13%)\n",
      "  Feature 15: 23/197 (12%)\n",
      "  Feature 14: 22/197 (11%)\n",
      "  Feature 0: 21/197 (11%)\n",
      "  Feature 12: 21/197 (11%)\n",
      "  Feature 6: 19/197 (10%)\n"
     ]
    }
   ],
   "source": [
    "# Count features in positive set\n",
    "feature_counts = {}\n",
    "for i in pos_indices:\n",
    "    for f in repr_features[i]:\n",
    "        feature_counts[f] = feature_counts.get(f, 0) + 1\n",
    "\n",
    "sorted_features = sorted(feature_counts.items(), key=lambda x: -x[1])\n",
    "print(\"Feature counts in positive set:\")\n",
    "for f, count in sorted_features:\n",
    "    print(f\"  Feature {f}: {count}/{len(pos_indices)} ({100*count/len(pos_indices):.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nullspace-header",
   "metadata": {},
   "source": [
    "## Nullspace Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "nullspace-svd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:13:37 | INFO | Nullspace computation:\n",
      "  n_neg=804, rms_norm=1.1916\n",
      "  epsilon_tilde = sqrt(804) * 1.1916 * 0.0 = 0.000001\n",
      "  singular values below threshold: 1\n",
      "  first SV below threshold: 0.000001\n"
     ]
    }
   ],
   "source": [
    "nullspace = compute_nullspace(representations, neighbor_indices, 0.0, neg_tau=ext_config.neg_tau, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3f54f1c6-2880-4d12-8406-7580ea1f4319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1894,  0.3829,  0.2578, -0.2098,  0.3358,  0.1459,  0.1695,  0.1030,\n",
       "          0.4089,  0.2581, -0.0641, -0.1452,  0.4965, -0.0752,  0.0037, -0.1495]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nullspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2754e404-f799-46ea-beb2-a2ba12cbcf95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a0dd8cb0-a7f0-491f-badc-c7b298e8a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feautre 0 is in nullspace\n",
      "Feautre 1 is in nullspace\n",
      "Feautre 2 is in nullspace\n",
      "Feautre 3 is in nullspace\n",
      "Feautre 4 is in nullspace\n",
      "Feautre 5 is in nullspace\n",
      "Feautre 6 is in nullspace\n",
      "Feautre 7 is in nullspace\n",
      "Feautre 8 is in nullspace\n",
      "Feautre 9 is NOT in nullspace\n",
      "Feautre 10 is in nullspace\n",
      "Feautre 11 is in nullspace\n",
      "Feautre 12 is in nullspace\n",
      "Feautre 13 is in nullspace\n",
      "Feautre 14 is in nullspace\n",
      "Feautre 15 is in nullspace\n"
     ]
    }
   ],
   "source": [
    "for i, feature in enumerate(features):\n",
    "    coeffs = nullspace @ feature\n",
    "    is_in_nullspace = torch.isclose((coeffs ** 2).sum(), torch.tensor(0.0))\n",
    "    if is_in_nullspace:\n",
    "        print(f\"Feautre {i} is in nullspace\")\n",
    "    else:\n",
    "        print(f\"Feautre {i} is NOT in nullspace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraction-header",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "extraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:13:55 | INFO | Feature extraction:\n",
      "  n_neighbors=197\n",
      "  first SV=9.4144, second SV=0.0000\n",
      "  ratio=15029061.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best match: feature 9 with alignment 1.0000\n",
      "Top 5 alignments: torch.return_types.topk(\n",
      "values=tensor([1.0000e+00, 1.0431e-07, 7.4506e-08, 5.7742e-08, 5.4017e-08]),\n",
      "indices=tensor([ 9,  6, 12,  0, 15]))\n"
     ]
    }
   ],
   "source": [
    "if nullspace.shape[0] > 0:\n",
    "    extracted = extract_feature(representations, neighbor_indices, nullspace, verbose=True)\n",
    "    \n",
    "    # Check alignment with ground truth features\n",
    "    alignments = torch.abs(extracted @ features.T)\n",
    "    best_match = alignments.argmax().item()\n",
    "    best_alignment = alignments[best_match].item()\n",
    "    \n",
    "    print(f\"Best match: feature {best_match} with alignment {best_alignment:.4f}\")\n",
    "    print(f\"Top 5 alignments: {alignments.topk(5)}\")\n",
    "else:\n",
    "    print(\"Empty nullspace!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-header",
   "metadata": {},
   "source": [
    "## Manual Investigation\n",
    "\n",
    "Add your own debugging cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "if nullspace.shape[0] == 0:\n",
    "    raise ValueError(\"Nullspace is empty, cannot extract feature\")\n",
    "\n",
    "# Get neighbor representations: (m, d) - rows are vectors\n",
    "neighbors = representations[neighbor_indices]\n",
    "\n",
    "# Project ALL neighbors onto nullspace\n",
    "# For row vectors: projected = X @ nullspace.T @ nullspace\n",
    "# This applies the projection matrix P = nullspace.T @ nullspace to each row\n",
    "projected = neighbors @ nullspace.T @ nullspace  # (m, d)\n",
    "\n",
    "# SVD to find direction of maximum variance\n",
    "# projected = U @ diag(S) @ Vh\n",
    "# Vh[0] (first row) is the dominant direction in d-space\n",
    "_, S, Vh = torch.linalg.svd(projected, full_matrices=False)\n",
    "\n",
    "# First right singular vector is the feature (already unit norm)\n",
    "feature = Vh[0]  # (d,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b97f1d74-cecd-43b3-b7f1-2051d5cdbd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.4144)\n",
      "tensor(6.1641e-07)\n",
      "tensor(1.0047e-07)\n",
      "tensor(9.0771e-08)\n",
      "tensor(8.1612e-08)\n",
      "tensor(7.0151e-08)\n",
      "tensor(6.1893e-08)\n",
      "tensor(5.4658e-08)\n",
      "tensor(4.2041e-08)\n",
      "tensor(3.9400e-08)\n",
      "tensor(3.5088e-08)\n",
      "tensor(3.3267e-08)\n",
      "tensor(2.3394e-08)\n",
      "tensor(1.9129e-08)\n",
      "tensor(1.3865e-08)\n",
      "tensor(8.1618e-10)\n"
     ]
    }
   ],
   "source": [
    "for s in S:\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
