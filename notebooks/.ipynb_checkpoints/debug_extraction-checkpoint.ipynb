{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Debug Feature Extraction\n",
    "\n",
    "Step-by-step investigation of the extraction algorithm with k>1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.config import SyntheticConfig, ExtractionConfig\n",
    "from src.synthetic import generate_feature_basis, generate_representations\n",
    "from src.extraction import (\n",
    "    cluster_by_neighbors,\n",
    "    resolve_tau,\n",
    "    compute_nullspace,\n",
    "    extract_feature,\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": "syn_config = SyntheticConfig(\n    d=16,\n    n=16,\n    epsilon=0.0,\n    num_representations=1000,\n    sparsity_mode=\"bernoulli_gaussian\",  # Options: \"fixed\", \"bernoulli_gaussian\"\n    k=3,  # For bernoulli_gaussian: theta = k/n, E[||z||_0] = k\n    coef_min_floor=0.5,  # Only used for non-BG modes\n    positive_only=False,  # BG allows negative by default\n)\next_config = ExtractionConfig(\n    tau=0.5,\n    neg_tau=0.05,\n    epsilon=0.0,\n)\n\nprint(f\"d={syn_config.d}, n={syn_config.n}, k={syn_config.k}\")\nprint(f\"sparsity_mode={syn_config.sparsity_mode}\")\nprint(f\"tau={ext_config.tau}, neg_tau={ext_config.neg_tau}\")"
  },
  {
   "cell_type": "markdown",
   "id": "gen-header",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = generate_feature_basis(syn_config.d, syn_config.n, syn_config.epsilon)\n",
    "representations, coefficients = generate_representations(features, syn_config)\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Representations shape: {representations.shape}\")\n",
    "print(f\"Coefficients shape: {coefficients.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_features(coef_row: torch.Tensor) -> set[int]:\n",
    "    return set(torch.where(coef_row != 0)[0].tolist())\n",
    "\n",
    "repr_features = [get_active_features(coefficients[i]) for i in range(syn_config.num_representations)]\n",
    "\n",
    "# Show first few\n",
    "for i in range(5):\n",
    "    print(f\"Repr {i}: active features = {repr_features[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sim-header",
   "metadata": {},
   "source": [
    "## Cosine Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosine-sim",
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = torch.norm(representations, dim=1)\n",
    "cos_sim_matrix = (representations @ representations.T) / (norms[:, None] * norms[None, :] + 1e-8)\n",
    "\n",
    "# Pick a specific representation to analyze\n",
    "target_idx = 0\n",
    "target_features = repr_features[target_idx]\n",
    "print(f\"Target repr {target_idx} has features: {target_features}\")\n",
    "\n",
    "# Separate representations by whether they share any feature with target\n",
    "shares_feature = [i for i in range(syn_config.num_representations) if repr_features[i] & target_features]\n",
    "no_shared_feature = [i for i in range(syn_config.num_representations) if not (repr_features[i] & target_features)]\n",
    "\n",
    "print(f\"Shares feature: {len(shares_feature)}, No shared: {len(no_shared_feature)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sim-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarities to target\n",
    "target_sims = cos_sim_matrix[target_idx]\n",
    "\n",
    "sims_sharing = target_sims[shares_feature].abs()\n",
    "sims_not_sharing = target_sims[no_shared_feature].abs()\n",
    "\n",
    "print(\"Sharing a feature:\")\n",
    "print(f\"  min={sims_sharing.min():.4f}, max={sims_sharing.max():.4f}, mean={sims_sharing.mean():.4f}\")\n",
    "print(\"Not sharing:\")\n",
    "print(f\"  min={sims_not_sharing.min():.4f}, max={sims_not_sharing.max():.4f}, mean={sims_not_sharing.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cluster-header",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clustering",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = resolve_tau(ext_config, syn_config)\n",
    "print(f\"Using tau = {tau:.4f}\")\n",
    "\n",
    "clusters = cluster_by_neighbors(representations, tau)\n",
    "print(f\"Number of clusters: {len(clusters)}\")\n",
    "\n",
    "# Show cluster sizes\n",
    "neighbor_sizes = [len(ns) for ns in clusters.keys()]\n",
    "print(f\"Neighbor set sizes: min={min(neighbor_sizes)}, max={max(neighbor_sizes)}, mean={sum(neighbor_sizes)/len(neighbor_sizes):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-cluster-header",
   "metadata": {},
   "source": [
    "## Analyze Single Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-cluster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick first cluster with >1 member\n",
    "cluster_list = [(ns, members) for ns, members in clusters.items() if len(ns) >= 2]\n",
    "neighbor_set, cluster_members = cluster_list[0]\n",
    "\n",
    "pos_indices = list(neighbor_set)\n",
    "neg_indices = [i for i in range(syn_config.num_representations) if i not in neighbor_set]\n",
    "\n",
    "print(f\"Positive set size: {len(pos_indices)}\")\n",
    "print(f\"Negative set size: {len(neg_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-counts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count features in positive set\n",
    "feature_counts = {}\n",
    "for i in pos_indices:\n",
    "    for f in repr_features[i]:\n",
    "        feature_counts[f] = feature_counts.get(f, 0) + 1\n",
    "\n",
    "sorted_features = sorted(feature_counts.items(), key=lambda x: -x[1])\n",
    "print(\"Feature counts in positive set:\")\n",
    "for f, count in sorted_features:\n",
    "    print(f\"  Feature {f}: {count}/{len(pos_indices)} ({100*count/len(pos_indices):.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nullspace-header",
   "metadata": {},
   "source": [
    "## Nullspace Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nullspace",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_indices = torch.tensor(pos_indices)\n",
    "\n",
    "# Filter non-neighbors by neg_tau\n",
    "neighbors = representations[neighbor_indices]\n",
    "neighbor_mean = neighbors.mean(dim=0)\n",
    "neighbor_mean_norm = torch.norm(neighbor_mean)\n",
    "\n",
    "all_norms = torch.norm(representations, dim=1)\n",
    "all_dots = representations @ neighbor_mean\n",
    "all_cosine_sims = torch.abs(all_dots / (all_norms * neighbor_mean_norm + 1e-8))\n",
    "\n",
    "# Count how many non-neighbors pass neg_tau filter\n",
    "neg_tau = ext_config.neg_tau\n",
    "filtered_neg_indices = [i for i in neg_indices if all_cosine_sims[i] <= neg_tau]\n",
    "print(f\"Non-neighbors passing neg_tau={neg_tau}: {len(filtered_neg_indices)}/{len(neg_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nullspace-svd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nullspace = compute_nullspace(representations, neighbor_indices, 0.0, neg_tau=ext_config.neg_tau, verbose=True)\n",
    "print(f\"Nullspace shape: {nullspace.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraction-header",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "if nullspace.shape[0] > 0:\n",
    "    extracted = extract_feature(representations, neighbor_indices, nullspace, verbose=True)\n",
    "    \n",
    "    # Check alignment with ground truth features\n",
    "    alignments = torch.abs(extracted @ features.T)\n",
    "    best_match = alignments.argmax().item()\n",
    "    best_alignment = alignments[best_match].item()\n",
    "    \n",
    "    print(f\"Best match: feature {best_match} with alignment {best_alignment:.4f}\")\n",
    "    print(f\"Top 5 alignments: {alignments.topk(5)}\")\n",
    "else:\n",
    "    print(\"Empty nullspace!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-header",
   "metadata": {},
   "source": [
    "## Manual Investigation\n",
    "\n",
    "Add your own debugging cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your debugging code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}