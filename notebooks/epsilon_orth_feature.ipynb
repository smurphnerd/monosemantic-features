{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "727a732b",
   "metadata": {},
   "source": [
    "# $\\epsilon$-Orthogonal Feature Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "784570cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11461f550>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from collections import Counter\n",
    "from src.synthetic import generate_feature_basis, generate_representations\n",
    "from src.config import SyntheticConfig, ExtractionConfig\n",
    "from src.extraction import resolve_tau, compute_nullspace, build_neighbor_matrix, find_monosemantic_targets\n",
    "from src.metrics import match_features\n",
    "\n",
    "torch.manual_seed(67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b24069fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_config = SyntheticConfig(\n",
    "    d=100,\n",
    "    n=110,\n",
    "    num_representations=5000,\n",
    "    sparsity_mode=\"bernoulli_gaussian\",\n",
    "    k=6,\n",
    "    positive_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96188db",
   "metadata": {},
   "source": [
    "## Generate $\\epsilon$-orthogonal feature frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "caafac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature frame: 110 features in 100 dimensions, coherence=0.0370\n"
     ]
    }
   ],
   "source": [
    "result = generate_feature_basis(syn_config.d, syn_config.n)\n",
    "ext_config = ExtractionConfig(epsilon=result.achieved_epsilon)\n",
    "print(f\"Feature frame: {syn_config.n} features in {syn_config.d} dimensions, coherence={result.achieved_epsilon:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80f2775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps, coeffs = generate_representations(result.features, syn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f7cc17",
   "metadata": {},
   "source": [
    "## Ground truth: which representations are truly monosemantic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4fb56166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 monosemantic representations (exactly 1 active feature)\n",
      "61/110 unique features appear monosemantically\n"
     ]
    }
   ],
   "source": [
    "true_mono_indices = set()\n",
    "mono_features = set()\n",
    "for i, coeff in enumerate(coeffs):\n",
    "    active = (coeff != 0)\n",
    "    if active.sum() == 1:\n",
    "        true_mono_indices.add(i)\n",
    "        mono_features.add(torch.nonzero(active).flatten()[0].item())\n",
    "\n",
    "print(f\"{len(true_mono_indices)} monosemantic representations (exactly 1 active feature)\")\n",
    "print(f\"{len(mono_features)}/{syn_config.n} unique features appear monosemantically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875a4223",
   "metadata": {},
   "source": [
    "## Evaluate `find_monosemantic_targets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19d3915d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau = 0.522555\n",
      "Targets returned: 923\n"
     ]
    }
   ],
   "source": [
    "tau = resolve_tau(ext_config, syn_config, epsilon=result.achieved_epsilon)\n",
    "neighbor_matrix = build_neighbor_matrix(reps, tau)\n",
    "neighbor_counts = neighbor_matrix.sum(dim=1)\n",
    "target_indices = find_monosemantic_targets(neighbor_matrix)\n",
    "target_set = set(target_indices.tolist())\n",
    "\n",
    "print(f\"tau = {tau:.6f}\")\n",
    "print(f\"Targets returned: {len(target_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b94b01fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives  (mono & target):     0\n",
      "False negatives (mono, not target):   84\n",
      "False positives (target, not mono):   923\n",
      "Recall: 0.00%\n"
     ]
    }
   ],
   "source": [
    "true_positives = true_mono_indices & target_set\n",
    "false_negatives = true_mono_indices - target_set\n",
    "false_positives = target_set - true_mono_indices\n",
    "\n",
    "print(f\"True positives  (mono & target):     {len(true_positives)}\")\n",
    "print(f\"False negatives (mono, not target):   {len(false_negatives)}\")\n",
    "print(f\"False positives (target, not mono):   {len(false_positives)}\")\n",
    "print(f\"Recall: {len(true_positives)/len(true_mono_indices):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diag-header",
   "metadata": {},
   "source": [
    "### Diagnosing the minimality filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "diag-fn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 truly mono representations were NOT selected as targets:\n",
      "  Rep 105: 70 neighbors, min in neighborhood: 12\n",
      "  Rep 149: 61 neighbors, min in neighborhood: 12\n",
      "  Rep 173: 62 neighbors, min in neighborhood: 12\n",
      "  Rep 245: 61 neighbors, min in neighborhood: 8\n",
      "  Rep 249: 60 neighbors, min in neighborhood: 6\n",
      "  Rep 274: 53 neighbors, min in neighborhood: 6\n",
      "  Rep 301: 48 neighbors, min in neighborhood: 9\n",
      "  Rep 348: 61 neighbors, min in neighborhood: 8\n",
      "  Rep 473: 67 neighbors, min in neighborhood: 13\n",
      "  Rep 478: 62 neighbors, min in neighborhood: 8\n"
     ]
    }
   ],
   "source": [
    "# Why are truly monosemantic representations failing the minimality filter?\n",
    "if false_negatives:\n",
    "    print(f\"{len(false_negatives)} truly mono representations were NOT selected as targets:\")\n",
    "    for idx in sorted(list(false_negatives))[:10]:\n",
    "        my_count = neighbor_counts[idx].item()\n",
    "        neighbors = neighbor_matrix[idx]\n",
    "        min_neighbor = neighbor_counts[neighbors].min().item()\n",
    "        print(f\"  Rep {idx}: {int(my_count)} neighbors, min in neighborhood: {int(min_neighbor)}\")\n",
    "else:\n",
    "    print(\"No false negatives\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "xd2q676yi5j",
   "source": "# For each false negative, find the min-neighbor rep in its neighborhood\n# and examine its relationship to the monosemantic feature direction\nimport torch.nn.functional as F\n\nfeatures = result.features  # (n, d) ground truth feature basis\n\nprint(\"For each mono rep: what is the min-neighbor rep, and how does it relate to the mono feature?\\n\")\nfor idx in sorted(list(false_negatives))[:10]:\n    mono_coeff = coeffs[idx]\n    mono_feat_idx = torch.nonzero(mono_coeff != 0).flatten()[0].item()\n    mono_feat = features[mono_feat_idx]  # the true feature direction\n    mono_coeff_val = mono_coeff[mono_feat_idx].item()\n\n    # Find the neighbor with the minimum neighbor count\n    neighbors = torch.where(neighbor_matrix[idx])[0]\n    min_count_in_neighborhood = neighbor_counts[neighbors].min().item()\n    min_neighbors = neighbors[neighbor_counts[neighbors] == min_count_in_neighborhood]\n    min_rep_idx = min_neighbors[0].item()\n\n    # Cosine similarity between the min-neighbor rep and the mono feature direction\n    min_rep = reps[min_rep_idx]\n    cossim_with_feat = F.cosine_similarity(min_rep.unsqueeze(0), mono_feat.unsqueeze(0)).item()\n\n    # Cosine similarity between the mono rep and the min-neighbor rep\n    cossim_mono_min = F.cosine_similarity(reps[idx].unsqueeze(0), min_rep.unsqueeze(0)).item()\n\n    # What features are active in the min-neighbor rep?\n    min_coeff = coeffs[min_rep_idx]\n    min_active = torch.nonzero(min_coeff != 0).flatten().tolist()\n    has_mono_feat = mono_feat_idx in min_active\n\n    # If it has the mono feature, what's its coefficient vs others?\n    min_coeff_for_mono = min_coeff[mono_feat_idx].item() if has_mono_feat else 0.0\n    min_active_vals = min_coeff[min_coeff != 0]\n    min_max_coeff = min_active_vals.abs().max().item()\n\n    print(f\"Mono rep {idx} (feature {mono_feat_idx}, coeff={mono_coeff_val:.3f}, {int(neighbor_counts[idx])} neighbors):\")\n    print(f\"  Min-neighbor rep {min_rep_idx}: {int(min_count_in_neighborhood)} neighbors, {len(min_active)} active features\")\n    print(f\"  cossim(min_rep, mono_feature_dir) = {cossim_with_feat:.4f}   (tau = {tau:.4f})\")\n    print(f\"  cossim(mono_rep, min_rep)          = {cossim_mono_min:.4f}\")\n    print(f\"  Has mono feature #{mono_feat_idx}? {has_mono_feat}\", end=\"\")\n    if has_mono_feat:\n        print(f\"  (coeff={min_coeff_for_mono:.3f}, max_coeff={min_max_coeff:.3f}, ratio={min_coeff_for_mono/min_max_coeff:.2f})\")\n    else:\n        print(f\"  â€” connected via cross-feature interference alone\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "diag-fp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive active feature counts:\n",
      "  3 active features: 2 (0.2%)\n",
      "  4 active features: 32 (3.5%)\n",
      "  5 active features: 66 (7.2%)\n",
      "  6 active features: 141 (15.3%)\n",
      "  7 active features: 159 (17.2%)\n",
      "  8 active features: 158 (17.1%)\n",
      "  9 active features: 160 (17.3%)\n",
      "  10 active features: 91 (9.9%)\n",
      "  11 active features: 63 (6.8%)\n",
      "  12 active features: 29 (3.1%)\n",
      "  13 active features: 15 (1.6%)\n",
      "  14 active features: 3 (0.3%)\n",
      "  15 active features: 3 (0.3%)\n",
      "  16 active features: 1 (0.1%)\n",
      "\n",
      "Dominance ratio (max_coeff / 2nd_coeff) for multi-feature FPs:\n",
      "  Mean=1.19, Median=1.15, Min=1.00, Max=1.98\n",
      "  Ratio > 3 (one dominates): 0/923\n",
      "  Ratio < 1.5 (no dominant):  877/923\n"
     ]
    }
   ],
   "source": [
    "# What do the false positives look like?\n",
    "fp_num_features = []\n",
    "fp_dominance_ratios = []\n",
    "\n",
    "for idx in false_positives:\n",
    "    c = coeffs[idx]\n",
    "    active = c[c != 0]\n",
    "    fp_num_features.append(len(active))\n",
    "    if len(active) >= 2:\n",
    "        sorted_abs = torch.sort(active.abs(), descending=True).values\n",
    "        fp_dominance_ratios.append((sorted_abs[0] / sorted_abs[1]).item())\n",
    "\n",
    "print(\"False positive active feature counts:\")\n",
    "for k, v in sorted(Counter(fp_num_features).items()):\n",
    "    print(f\"  {k} active features: {v} ({v/len(false_positives):.1%})\")\n",
    "\n",
    "if fp_dominance_ratios:\n",
    "    ratios = torch.tensor(fp_dominance_ratios)\n",
    "    print(f\"\\nDominance ratio (max_coeff / 2nd_coeff) for multi-feature FPs:\")\n",
    "    print(f\"  Mean={ratios.mean():.2f}, Median={ratios.median():.2f}, Min={ratios.min():.2f}, Max={ratios.max():.2f}\")\n",
    "    print(f\"  Ratio > 3 (one dominates): {(ratios > 3).sum().item()}/{len(ratios)}\")\n",
    "    print(f\"  Ratio < 1.5 (no dominant):  {(ratios < 1.5).sum().item()}/{len(ratios)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "diag-counts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All representations:  mean=30.7, median=30.0\n",
      "Targets:             mean=12.0, median=11.0\n",
      "Truly monosemantic:  mean=59.0, median=61.0\n"
     ]
    }
   ],
   "source": [
    "# Neighbor count distributions\n",
    "print(f\"All representations:  mean={neighbor_counts.float().mean():.1f}, median={neighbor_counts.float().median():.1f}\")\n",
    "print(f\"Targets:             mean={neighbor_counts[target_indices].float().mean():.1f}, median={neighbor_counts[target_indices].float().median():.1f}\")\n",
    "if true_mono_indices:\n",
    "    mono_counts = neighbor_counts[list(true_mono_indices)].float()\n",
    "    print(f\"Truly monosemantic:  mean={mono_counts.mean():.1f}, median={mono_counts.median():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posthoc-header",
   "metadata": {},
   "source": [
    "## Post-hoc spectral gap filtering\n",
    "\n",
    "Instead of pre-selecting targets via neighbor count minimality, run extraction on\n",
    "ALL unique neighbor-set representatives and use the SVD singular value spectrum to\n",
    "identify monosemantic ones: a large gap between $\\sigma_1$ and $\\sigma_2$ indicates\n",
    "a single dominant feature direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posthoc-extract",
   "metadata": {},
   "outputs": [],
   "source": "from tqdm.notebook import tqdm\n\nepsilon = ext_config.epsilon\n\n# Get ALL unique neighbor-set representatives (no minimality filter)\nseen_rows: dict[bytes, int] = {}\nall_representatives: list[int] = []\nfor i in range(neighbor_matrix.shape[0]):\n    row_key = neighbor_matrix[i].cpu().numpy().tobytes()\n    if row_key not in seen_rows:\n        seen_rows[row_key] = i\n        all_representatives.append(i)\n\nprint(f\"Total unique neighbor sets: {len(all_representatives)}\")\n\n# Run extraction on each, collecting singular value spectra\nresults = []\n\nfor idx in tqdm(all_representatives, desc=\"Extracting\"):\n    neighbor_mask = neighbor_matrix[idx]\n    neighbor_indices = torch.where(neighbor_mask)[0]\n\n    if len(neighbor_indices) < 2:\n        continue\n\n    try:\n        nullspace = compute_nullspace(reps, neighbor_indices, epsilon)\n        if nullspace.shape[0] == 0:\n            continue\n\n        neighbors = reps[neighbor_indices]\n        projected = neighbors @ nullspace.T @ nullspace\n\n        _, S, Vh = torch.linalg.svd(projected, full_matrices=False)\n        feature = Vh[0]\n\n        num_true = (coeffs[idx] != 0).sum().item()\n        gap = (S[0] / S[1]).item() if len(S) > 1 and S[1] > 1e-10 else float('inf')\n\n        results.append({\n            'idx': idx,\n            'feature': feature,\n            'singular_values': S,\n            'num_true_features': num_true,\n            'is_mono': num_true == 1,\n            'spectral_gap': gap,\n        })\n    except (ValueError, RuntimeError):\n        continue\n\nprint(f\"Successfully extracted from {len(results)} representatives\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posthoc-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral gap distributions: monosemantic vs multi-feature\n",
    "mono_gaps = [r['spectral_gap'] for r in results if r['is_mono']]\n",
    "poly_gaps = [r['spectral_gap'] for r in results if not r['is_mono']]\n",
    "\n",
    "mono_finite = torch.tensor([g for g in mono_gaps if g != float('inf')])\n",
    "poly_finite = torch.tensor([g for g in poly_gaps if g != float('inf')])\n",
    "\n",
    "print(f\"Monosemantic ({len(mono_gaps)} reps, {sum(1 for g in mono_gaps if g == float('inf'))} with inf gap):\")\n",
    "if len(mono_finite) > 0:\n",
    "    print(f\"  Mean={mono_finite.mean():.2f}, Median={mono_finite.median():.2f}, Min={mono_finite.min():.2f}, Max={mono_finite.max():.2f}\")\n",
    "\n",
    "print(f\"\\nMulti-feature ({len(poly_gaps)} reps, {sum(1 for g in poly_gaps if g == float('inf'))} with inf gap):\")\n",
    "if len(poly_finite) > 0:\n",
    "    print(f\"  Mean={poly_finite.mean():.2f}, Median={poly_finite.median():.2f}, Min={poly_finite.min():.2f}, Max={poly_finite.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posthoc-sweep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold sweep: precision/recall tradeoff for spectral gap filtering\n",
    "total_mono = sum(1 for r in results if r['is_mono'])\n",
    "\n",
    "print(f\"{'Threshold':>10} {'Selected':>8} {'True Mono':>10} {'Precision':>10} {'Recall':>8}\")\n",
    "for threshold in [1.5, 2.0, 3.0, 5.0, 8.0, 10.0, 15.0, 20.0]:\n",
    "    selected = [r for r in results if r['spectral_gap'] >= threshold]\n",
    "    selected_mono = [r for r in selected if r['is_mono']]\n",
    "    precision = len(selected_mono) / len(selected) if selected else 0\n",
    "    recall = len(selected_mono) / total_mono if total_mono > 0 else 0\n",
    "    print(f\"{threshold:>10.1f} {len(selected):>8} {len(selected_mono):>10} {precision:>10.1%} {recall:>8.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posthoc-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do high-spectral-gap extractions (even from multi-feature reps) recover true features?\n",
    "SPECTRAL_THRESHOLD = 5.0\n",
    "\n",
    "high_gap = [r for r in results if r['spectral_gap'] >= SPECTRAL_THRESHOLD]\n",
    "if high_gap:\n",
    "    extracted = torch.stack([r['feature'] for r in high_gap])\n",
    "    matching, scores = match_features(extracted, result.features, threshold=0.9)\n",
    "\n",
    "    print(f\"High spectral gap (>={SPECTRAL_THRESHOLD}) extractions: {len(high_gap)}\")\n",
    "    print(f\"  Matched to a true feature (|cossim| > 0.9): {len(matching)}\")\n",
    "    if len(matching) > 0:\n",
    "        matched_scores = scores[scores > 0]\n",
    "        print(f\"  Mean alignment of matches: {matched_scores.mean():.3f}\")\n",
    "\n",
    "    mono_high = [r for r in high_gap if r['is_mono']]\n",
    "    poly_high = [r for r in high_gap if not r['is_mono']]\n",
    "    print(f\"  From monosemantic reps: {len(mono_high)}\")\n",
    "    print(f\"  From multi-feature reps: {len(poly_high)}\")\n",
    "\n",
    "    if poly_high:\n",
    "        poly_extracted = torch.stack([r['feature'] for r in poly_high])\n",
    "        poly_matching, poly_scores = match_features(poly_extracted, result.features, threshold=0.9)\n",
    "        print(f\"  Multi-feature extractions matching a true feature: {len(poly_matching)}/{len(poly_high)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee779a-3950-4797-89a5-0ce9d84d9ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}