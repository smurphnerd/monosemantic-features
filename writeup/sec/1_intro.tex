\section{Introduction}

This is likely my final attempt at finding a solution to the problem of verifying the linear representation hypothesis (LRH).
The LRH's main idea is that, for large-scale transformer models like LLMs, you are able to decompose any of the model's intermediate representations into more fundamental concepts.
A byproduct of this assumption is that there exists a set of these fundamental concepts such that none of them can be broken down further, and that any representation, no matter how complex, can ultimately be described by a combination of these more fundamental concepts.

Being able to find these fundamental concepts is what I've been trying to figure out for the past year.
It has led me to ask interesting questions of myself, whether my own thoughts can be deconstructed similarly.
For example, if I'm feeling love for my girlfriend, perhaps this can be described neurologically as a set of neurons firing for the ``love'' concept, together with a set of neurons firing for the ``my girlfriend''.
And it is likely that these ``love'' neurons are the same neurons that fire when I think about the love for my family, and similarly, the ``my girlfriend'' neurons are likely the same neurons that fire when I think about how annoying my girlfriend can be.
It is only by combining these sets of neurons that I get the unique thought of ``love for my girlfriend.''

If you accept that complex thoughts can be decomposed in such a way, the next question you may ask is which thoughts or concepts cannot be decomposed further.
In other words, what are the most fundamental concepts that constitute all other thoughts?

Going back to my example, we can imagine that the neurons responsible for representing ``my girlfriend'' may be a combination of more fundamental sets of neurons such as the neurons responsible for the ``person'', ``girl'', and ``partner'' concepts.
And perhaps these neurons can be further decomposed.
However, when we look at the neurons for ``love'' it's a lot harder to imagine how they can be decomposed further.
I'm not saying that ``love'' is necessarily a fundamental concept, but I just wanted to illustrate the idea that there are perhaps these `base' concepts that we're incapable of breaking down or explaining further.
Perhaps they are the feelings or models of the world that we are born with, something developed through evolutionary processes, and that everything else we know or think is just some combination of them.

Although this section turned out more philosophical than I was intending, it is important to illustrate this idea of being able to decompose complex thoughts as this is the essence of the LRH and is how many believe LLMs work.
I hope it also gives you an insight into how I like to approach these types of problems.
Today's AI systems were heavily inspired by the human brain, so when it comes to trying to understand how they work, I believe looking inwards towards how we work is a good place to start.

\Cref{sec:background} will provide background on some of the assumptions that I will be operating under and \Cref{sec:methodology} will outline the method I plan to implement for finding these fundamental concepts.
